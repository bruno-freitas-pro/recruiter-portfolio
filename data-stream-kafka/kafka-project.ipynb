{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: install dependencies, if not installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sqlalchemy ipython-sql kafka-python\n",
    "%conda install -c cyclus java-jre"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Download Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -P /tmp https://archive.apache.org/dist/kafka/2.8.0/kafka_2.12-2.8.0.tgz"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Extract Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xzf /tmp/kafka_2.12-2.8.0.tgz -C /tmp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7: Start Zookeeper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Open a new terminal and run the following command:\n",
    "* `/tmp/kafka_2.12-2.8.0/bin/zookeeper-server-start.sh /tmp/kafka_2.12-2.8.0/config/zookeeper.properties`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 8: Start Kafka server"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Open a new terminal and run the following command:\n",
    "* `/tmp/kafka_2.12-2.8.0/bin/kafka-server-start.sh /tmp/kafka_2.12-2.8.0/config/server.properties`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 9: Create a topic named toll in kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/tmp/kafka_2.12-2.8.0/bin/kafka-topics.sh --create --topic toll --bootstrap-server localhost:9092"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 10: Download toll traffic simulator program <<Thanks, IBM!>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -P /tmp https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0250EN-SkillsNetwork/labs/Final%20Assignment/toll_traffic_generator.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 11: Customize the generator program, changing topic to \"toll\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Open a new terminal and type `nano /tmp/toll_traffic_generator.py`\n",
    "* Change the TOPIC variable to \"toll\"\n",
    "* Press CTRL+O to save\n",
    "* Press ENTER/RETURN to confirm\n",
    "* Press CTRL+X to exit nano"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 12: Run the Toll Traffic Simulator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Open a new terminal and type: `python3 /tmp/toll_traffic_generator.py`\n",
    "* In my case, the command was slightly different: `~/miniconda3/envs/mytest/bin/python /tmp/toll_traffic_generator.py`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 13: Download streaming data reader (consumer) <<Thanks, IBM!>>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* You don't need to download if you don't want to. Simply skip this step and go to step 14.\n",
    "* Font: https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0250EN-SkillsNetwork/labs/Final%20Assignment/streaming_data_reader.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 14: Customize the consumer program to write into a SQLite database table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo -e 'from datetime import datetime\n",
    "from kafka import KafkaConsumer\n",
    "import sqlite3\n",
    "\n",
    "TOPIC=\"toll\"\n",
    "\n",
    "print(\"Connecting to the database\")\n",
    "try:\n",
    "    connection = sqlite3.connect(\"file:/tmp/kafka-project.db\", uri=True)\n",
    "except Exception:\n",
    "    print(\"Could not connect to database\")\n",
    "else:\n",
    "    print(\"Connected to database\")\n",
    "cursor = connection.cursor()\n",
    "\n",
    "#Create table\n",
    "print(\"creating table\")\n",
    "try:\n",
    "    cursor.execute(\"\"\"create table livetolldata(\n",
    "        timestamp datetime,\n",
    "        vehicle_id int,\n",
    "        vehicle_type char(15),\n",
    "        toll_plaza_id smallint\n",
    "        );\"\"\")\n",
    "except Exception:\n",
    "    print(\"table already exists\")\n",
    "else:\n",
    "    print(\"table created successfully\")\n",
    "\n",
    "print(\"Connecting to Kafka\")\n",
    "consumer = KafkaConsumer(TOPIC)\n",
    "print(\"Connected to Kafka\")\n",
    "print(f\"Reading messages from the topic {TOPIC}\")\n",
    "for msg in consumer:\n",
    "\n",
    "    # Extract information from kafka\n",
    "    message = msg.value.decode(\"utf-8\")\n",
    "\n",
    "    # Transform the date format to suit the database schema\n",
    "    (timestamp, vehicle_id, vehicle_type, plaza_id) = message.split(\",\")\n",
    "\n",
    "    dateobj = datetime.strptime(timestamp, \"%a %b %d %H:%M:%S %Y\")\n",
    "    timestamp = dateobj.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    # Loading data into the database table\n",
    "\n",
    "    sql = \"insert into livetolldata values(?,?,?,?)\"\n",
    "    result = cursor.execute(sql, (timestamp, vehicle_id, vehicle_type, plaza_id))\n",
    "    print(f\"{timestamp}: A {vehicle_type} was inserted into the database\")\n",
    "    connection.commit()\n",
    "connection.close()' > /tmp/streaming_data_reader.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 15: Run the consumer script"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Open a new terminal and type: `python3 /tmp/streaming_data_reader.py`\n",
    "* In my case, the command was slightly different: `~/miniconda3/envs/mytest/bin/python /tmp/streaming_data_reader.py`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 16: Verify that streamed data is being collected in the database table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql sqlite:////tmp/kafka-project.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT * FROM livetolldata order by timestamp desc LIMIT 10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3156d5e031489879d21d24b1930f2a20eafcb9b25c0e902ed513e14b5548b057"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
